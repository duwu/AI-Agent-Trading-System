
"""
OpenAIåˆ†æå™¨ - openai>=1 ç»Ÿä¸€å®ç°
ç»Ÿä¸€ä½¿ç”¨ OpenAI(...).chat.completions.createï¼Œå¹¶æ”¯æŒè‡ªå®šä¹‰ base_url ä¸æ¨¡å‹ã€‚
"""

import asyncio
from typing import Dict, Any, Optional
import json
import logging
import os
import requests

logger = logging.getLogger(__name__)

class OpenAIAnalyzer:
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        # ç¡®ä¿åŠ è½½ç¯å¢ƒå˜é‡
        from dotenv import load_dotenv
        load_dotenv()

        # ä»ç¯å¢ƒè¯»å–é…ç½®
        self.api_key = api_key or os.getenv("OPENAI_API_KEY", "")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL", "https://jeniya.cn/v1")
        # æ¨¡å‹ä¼˜å…ˆçº§ï¼šENV -> åˆç†é»˜è®¤
        self.model = os.getenv("OPENAI_MODEL", os.getenv("OPENAI_CHAT_MODEL", "gpt-5"))

        self.client = None
        # æ‡’åˆå§‹åŒ–ï¼šåªè¦æœ‰ key å°±æ ‡è®°å¯ç”¨ï¼›è°ƒç”¨æ—¶æŠ¥é”™å†é™çº§
        self.is_available = bool(self.api_key)
        # ä¼ è¾“ä¼˜å…ˆçº§ï¼šsdk | httpï¼ˆæŸäº›ä»£ç†æ›´å…¼å®¹ httpï¼‰
        self.transport = os.getenv("OPENAI_PREFERRED_TRANSPORT", "sdk").lower()
        # æ¸©åº¦ç­–ç•¥ï¼šé»˜è®¤ä¸ä¸‹å‘ï¼ˆå¤šæ•°ä»£ç†é»˜è®¤=1 ä¸”ä¸æ¥å—è‡ªå®šä¹‰ï¼‰
        self.temperature_env = os.getenv("OPENAI_TEMPERATURE")
        self.send_temperature = os.getenv("OPENAI_SEND_TEMPERATURE", "false").lower() in ("1", "true", "yes")
        # å¦‚æœæ˜¯è‡ªå®šä¹‰ä»£ç†ï¼ˆéå®˜æ–¹ï¼‰ï¼Œé»˜è®¤ä¼˜å…ˆä½¿ç”¨ http
        if self.base_url and "api.openai.com" not in self.base_url and os.getenv("OPENAI_PREFERRED_TRANSPORT") is None:
            self.transport = "http"

        # åˆå§‹åŒ–æ–°ç‰ˆ OpenAI å®¢æˆ·ç«¯ï¼ˆopenai>=1ï¼‰
        self._initialize_client()

    def _initialize_client(self):
        """å®‰å…¨åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆopenai>=1ï¼‰"""
        if not self.is_available:
            logger.warning("OpenAI APIå¯†é’¥æœªè®¾ç½®ï¼Œè·³è¿‡åˆå§‹åŒ–")
            return
        try:
            from openai import OpenAI
            # ç»Ÿä¸€ä½¿ç”¨å¯é…ç½®çš„ base_urlï¼Œå…¼å®¹ç¬¬ä¸‰æ–¹ä¸­è½¬
            self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
            logger.info(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ (base_url={self.base_url}, model={self.model})")
        except Exception as e:
            logger.warning(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥({e})ï¼Œå°†å°è¯•ä½¿ç”¨HTTPé€šé“ç›´æ¥è®¿é—® /chat/completions")
            self.client = None
    
    def analyze_market_context(self, symbol: str, price_data: Dict[str, Any], technical_indicators: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¸‚åœºä¸Šä¸‹æ–‡ - å…¼å®¹æ–¹æ³•"""
        if not self.is_available:
            return {
                "market_state": "neutral",
                "recommendation": "hold",
                "strength": 0.5,
                "reasoning": "OpenAIåˆ†æä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤å€¼"
            }
        
        try:
            # æ„å»ºåˆ†ææ•°æ®
            analysis_data = {
                'market': {
                    'symbol': symbol,
                    'current_price': price_data.get('price', 0),
                    'price_change_24h': price_data.get('price_change_24h', 0),
                    'volume_24h': price_data.get('volume_24h', 0),
                    'rsi': technical_indicators.get('rsi', 50),
                    'macd': technical_indicators.get('macd', 'neutral'),
                    'bb_position': technical_indicators.get('bb_position', 'middle'),
                    'trend_strength': technical_indicators.get('trend_strength', 'moderate')
                }
            }
            
            # ä½¿ç”¨ç»¼åˆåˆ†ææ–¹æ³•
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            result = loop.run_until_complete(self.analyze_comprehensive(analysis_data))
            loop.close()
            
            # è½¬æ¢ä¸ºæœŸæœ›çš„æ ¼å¼
            return {
                "market_state": result.get("trend", "neutral"),
                "recommendation": result.get("action", "hold").lower(),
                "strength": result.get("confidence", 0.5),
                "reasoning": result.get("reasoning", "AIå¸‚åœºåˆ†æ")
            }
            
        except Exception as e:
            logger.error(f"OpenAIå¸‚åœºä¸Šä¸‹æ–‡åˆ†æå¤±è´¥: {e}")
            return {
                "market_state": "neutral", 
                "recommendation": "hold",
                "strength": 0.5,
                "reasoning": f"åˆ†æå¤±è´¥: {str(e)}"
            }
    
    def test_connection(self) -> bool:
        """æµ‹è¯•OpenAIè¿æ¥"""
        if not self.is_available or not self.client:
            return False

        try:
            # å°è¯•ä¸€ä¸ªç®€å•çš„è°ƒç”¨ï¼ˆæ–°ç‰ˆAPIï¼‰
            _ = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "ping"}],
            )
            logger.info("OpenAIè¿æ¥æµ‹è¯•æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"OpenAIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            self.is_available = False
            return False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–åˆ†æå™¨çŠ¶æ€"""
        return {
            "available": self.is_available,
            "has_api_key": bool(self.api_key and self.api_key != ""),
            "base_url": self.base_url,
            "client_type": type(self.client).__name__ if self.client else None
        }
    
    async def analyze_comprehensive(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """ç»¼åˆåˆ†æ - åŸºäº openai>=1 çš„ chat.completions æ¥å£ï¼Œå¸¦é™çº§"""
        # ä»…å½“æ²¡æœ‰å¯ç”¨çš„ API Key æ—¶ç›´æ¥é™çº§
        if not self.is_available:
            return self._fallback_analysis(data, reason="missing_api_key_or_disabled")

        try:
            prompt = self._create_analysis_prompt(data)

            candidates: list[str] = []
            if self.model:
                candidates.append(self.model)
            candidates += ["gpt-4o-mini", "gpt-4o", "gpt-4.1-mini", "gpt-3.5-turbo"]

            # è‹¥åå¥½ http æˆ– SDK å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œåˆ™ä¼˜å…ˆèµ° http
            if self.transport == "http" or self.client is None:
                try:
                    http_text = self._http_chat_completion(prompt, candidates[0] if candidates else self.model)
                    if http_text:
                        logger.info("OpenAI HTTPä¼˜å…ˆé€šé“æˆåŠŸ")
                        return self._parse_ai_response(http_text)
                except Exception as e_http_first:
                    logger.warning(f"HTTPä¼˜å…ˆé€šé“å¤±è´¥ï¼Œå›é€€SDK: {e_http_first}")

            last_err = None
            # SDK æ¨¡å¼å°è¯•
            for mdl in candidates:
                try:
                    kwargs = {
                        "model": mdl,
                        "messages": [{"role": "user", "content": prompt}],
                    }
                    if self.send_temperature and self.temperature_env:
                        try:
                            kwargs["temperature"] = float(self.temperature_env)
                        except Exception:
                            pass
                    if self.client is None:
                        raise RuntimeError("SDK client not initialized")
                    resp = self.client.chat.completions.create(**kwargs)
                    analysis_text = resp.choices[0].message.content if resp and resp.choices else None
                    if analysis_text:
                        if mdl != self.model:
                            logger.info(f"OpenAIæ¨¡å‹å›é€€æˆåŠŸ: ä½¿ç”¨ {mdl}")
                            self.model = mdl
                        return self._parse_ai_response(analysis_text)
                    else:
                        logger.warning(f"OpenAIè¿”å›ç©ºå“åº” (model={mdl})ï¼Œå°è¯•ä¸‹ä¸€ä¸ª")
                        last_err = RuntimeError("empty choices")
                except Exception as ie:
                    # å¦‚æœ SDK å¤±è´¥ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªå€™é€‰
                    last_err = ie
                    logger.warning(f"OpenAIè°ƒç”¨å¤±è´¥ (model={mdl}): {ie}")

            # SDK å¤šæ¨¡å‹å‡å¤±è´¥æˆ–ç©ºå“åº”æ—¶ï¼Œå°è¯• HTTP ç›´è¿åå¤‡
            try:
                http_text = self._http_chat_completion(prompt, candidates[0] if candidates else self.model)
                if http_text:
                    logger.info("OpenAI HTTPåå¤‡é€šé“æˆåŠŸ")
                    return self._parse_ai_response(http_text)
            except Exception as he:
                last_err = he
                logger.warning(f"OpenAI HTTPåå¤‡é€šé“å¤±è´¥: {he}")

            if last_err:
                logger.error(f"OpenAIå…¨éƒ¨å°è¯•å¤±è´¥ï¼Œä½¿ç”¨é™çº§åˆ†æ: {last_err}")
                return self._fallback_analysis(data, reason=str(last_err))
            else:
                logger.warning("OpenAIè¿”å›ç©ºå“åº”")
                return self._fallback_analysis(data, reason="empty_response")

        except Exception as e:
            logger.error(f"OpenAIåˆ†æå¤±è´¥: {e}")
            return self._fallback_analysis(data, reason=str(e))

    # ================= æ–°å¢é€šç”¨èŠå¤©å°è£… =================
    def _chat(self, prompt: str, model: Optional[str] = None) -> str:
        """ç»Ÿä¸€çš„èŠå¤©è°ƒç”¨ï¼šHTTPä¼˜å…ˆï¼Œå¤±è´¥åå°è¯•SDKï¼›å¤±è´¥æŠ›å¼‚å¸¸ï¼Œä¸åšé™çº§ã€‚"""
        model_to_use = model or self.model
        last_err: Optional[Exception] = None
        # HTTP first
        try:
            return self._http_chat_completion(prompt, model_to_use) or ""
        except Exception as e:
            last_err = e
        # SDK fallback strictly (ä»…åœ¨å­˜åœ¨clientæ—¶)
        if self.client is not None:
            try:
                kwargs = {"model": model_to_use, "messages": [{"role": "user", "content": prompt}]}
                if self.send_temperature and self.temperature_env:
                    try:
                        kwargs["temperature"] = float(self.temperature_env)
                    except Exception:
                        pass
                resp = self.client.chat.completions.create(**kwargs)
                if resp and resp.choices:
                    return resp.choices[0].message.content or ""
                raise RuntimeError("SDKè¿”å›ç©ºå“åº”")
            except Exception as e2:
                last_err = e2
        raise RuntimeError(f"èŠå¤©è°ƒç”¨å¤±è´¥: {last_err}")

    # ================= é«˜çº§æ–°é—»æƒ…æ„Ÿåˆ†æ =================
    def analyze_news_sentiment_advanced(self, headlines: list[str], symbol: str) -> Dict[str, Any]:
        if not self.is_available:
            raise RuntimeError("OpenAIä¸å¯ç”¨ï¼Œæ— æ³•æ‰§è¡Œæ–°é—»æƒ…æ„Ÿåˆ†æ (ä¸¥æ ¼æ¨¡å¼)")
        if not headlines:
            raise RuntimeError("æ— æ–°é—»æ ‡é¢˜å¯åˆ†æ")
        # é™åˆ¶æ¡æ•°ï¼Œå‡å°‘token
        top_headlines = headlines[:12]
        joined = "\n".join(f"- {h}" for h in top_headlines)
        prompt = f"""
ä½ æ˜¯ä¸“ä¸šåŠ å¯†å¸‚åœºæ–°é—»æƒ…ç»ªåˆ†æå¸ˆã€‚è¯·è¯»å–ä¸‹åˆ—ä¸ {symbol} ç›¸å…³çš„æ–°é—»æ ‡é¢˜ï¼Œè¿›è¡Œæƒ…ç»ªå®šé‡è¯„ä¼°ï¼š
{joined}

è¯·è¾“å‡º JSONï¼Œå­—æ®µï¼š{{"sentiment":"bullish|bearish|neutral","sentiment_score":0.32,"keywords":["...","..."],"summary":"ä¸€å¥è¯æ‘˜è¦"}}
è¦æ±‚ï¼š
1. sentiment_score èŒƒå›´ -1~1ï¼Œ>0 çœ‹æ¶¨ï¼Œ<0 çœ‹è·Œï¼Œ0 ä¸­æ€§ã€‚
2. åªè¾“å‡º JSONï¼Œä¸è¦é™„åŠ è¯´æ˜ã€‚
""".strip()
        raw = self._chat(prompt)
        import re, json
        match = re.search(r'\{.*\}', raw, re.DOTALL)
        if not match:
            raise RuntimeError("æœªæ‰¾åˆ°JSONç»“æœ (æ–°é—»æƒ…æ„Ÿ)")
        txt = match.group(0)
        try:
            data = json.loads(txt)
        except Exception as e:
            raise RuntimeError(f"æ–°é—»æƒ…æ„ŸJSONè§£æå¤±è´¥: {e}")
        score = data.get("sentiment_score")
        try:
            score = float(score)
        except Exception:
            raise RuntimeError("sentiment_score éæ•°å€¼")
        if score < -1 or score > 1:
            raise RuntimeError("sentiment_score è¶…å‡ºèŒƒå›´")
        return {
            "sentiment": data.get("sentiment", "neutral"),
            "sentiment_score": score,
            "keywords": data.get("keywords", []),
            "summary": data.get("summary", "")
        }

    # ================= äº¤æ˜“æ´å¯Ÿç”Ÿæˆ =================
    def generate_trading_insights(self, symbol: str, context: Dict[str, Any]) -> Dict[str, Any]:
        if not self.is_available:
            raise RuntimeError("OpenAIä¸å¯ç”¨ï¼Œæ— æ³•ç”Ÿæˆäº¤æ˜“æ´å¯Ÿ (ä¸¥æ ¼æ¨¡å¼)")
        price = context.get("market", {}).get("price") or context.get("market", {}).get("current_price", 0)
        prompt = f"""
ä½ æ˜¯èµ„æ·±é‡åŒ–ä¸æŠ€æœ¯åˆ†æé¡¾é—®ã€‚åŸºäºå·²èšåˆçš„åˆ†æä¸Šä¸‹æ–‡ï¼ˆJSONç»“æ„å·²åœ¨ç³»ç»Ÿå†…éƒ¨ï¼Œä¸å†é‡å¤æä¾›ï¼‰ï¼Œè¯·é’ˆå¯¹ {symbol} ç»™å‡ºä¸¥æ ¼ JSON ç­–ç•¥ï¼š
å­—æ®µï¼š{{"action":"ä¹°å…¥|å–å‡º|è§‚æœ›","rationale":"æ ¸å¿ƒç†ç”±","targets":[æ•°å­—,æ•°å­—],"stop_loss":æ•°å­—,"add_position_price":æ•°å­—}}
è¦æ±‚ï¼š
1. targets æ•°ç»„é•¿åº¦ 1-2, é€’å¢ï¼›
2. æ•°å€¼ä¸ºæµ®ç‚¹ï¼Œä¸åŠ å¼•å·ï¼›
3. æ ¹æ®å½“å‰ä»·æ ¼ {price} ç»™å‡ºç›¸å¯¹åˆç†ç™¾åˆ†æ¯”ï¼ˆ5%-12%åŒºé—´ç›®æ ‡, æ­¢æŸ2%-4%, åŠ ä»“å›è°ƒ1%-3%ï¼‰ã€‚
åªè¾“å‡º JSONã€‚
""".strip()
        raw = self._chat(prompt)
        import re, json
        m = re.search(r'\{.*\}', raw, re.DOTALL)
        if not m:
            raise RuntimeError("æœªæ‰¾åˆ°äº¤æ˜“æ´å¯ŸJSON")
        j = m.group(0)
        data = json.loads(j)
        # è§„èŒƒåŒ–
        def _num(v):
            try:
                return float(v)
            except Exception:
                return None
        targets = data.get("targets") or []
        targets = [ _num(x) for x in targets if _num(x) is not None ]
        return {
            "action": data.get("action", "è§‚æœ›"),
            "rationale": data.get("rationale", ""),
            "targets": targets,
            "stop_loss": _num(data.get("stop_loss")),
            "add_position_price": _num(data.get("add_position_price"))
        }
    
    # æ³¨æ„ï¼šå·²åœ¨ä¸Šæ–¹æä¾› test_connection çš„å®ç°ï¼Œè¿™é‡Œç§»é™¤é‡å¤å®šä¹‰

    def _http_chat_completion(self, prompt: str, model: Optional[str]) -> Optional[str]:
        """ç›´æ¥é€šè¿‡ HTTP è°ƒç”¨ /chat/completionsï¼Œå…¼å®¹ç¬¬ä¸‰æ–¹ä»£ç†å·®å¼‚"""
        base_url = self.base_url.rstrip('/')
        url = f"{base_url}/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "User-Agent": "python-requests/2.x ai-agent-trading-system",
        }
        base_payload = {
            "model": model or self.model,
            "messages": [{"role": "user", "content": prompt}],
        }
        # é»˜è®¤ä¸ä¸‹å‘æ¸©åº¦ï¼ˆè®©ä»£ç†ä½¿ç”¨é»˜è®¤=1ï¼‰ï¼›å¦‚æ˜¾å¼å¼€å¯ï¼Œåˆ™å…ˆç”¨è‡ªå®šä¹‰ï¼Œå†å°è¯•ä¸ä¸‹å‘å’Œ1.0
        try_temps = [None]
        if self.send_temperature and self.temperature_env:
            try:
                try_temps = [float(self.temperature_env), None, 1.0]
            except Exception:
                try_temps = [None, 1.0]
        last_exc = None
        data = None
        for t in try_temps:
            try:
                payload = dict(base_payload)
                if t is not None:
                    payload["temperature"] = t
                # æ›´å®½æ¾çš„è¶…æ—¶ (connect, read)
                resp = requests.post(url, headers=headers, json=payload, timeout=(10, 60))
                resp.raise_for_status()
                data = resp.json()
                break
            except Exception as e:
                last_exc = e
                continue
        if data is None:
            if last_exc:
                raise last_exc
            raise RuntimeError("HTTP fallback failed with unknown error")
        choices = data.get("choices", []) or []
        if not choices:
            logger.warning(f"HTTPåå¤‡è¿”å›æ— choices: {data}")
            return None
        msg = choices[0].get("message") or {}
        return msg.get("content")
    
    def _create_analysis_prompt(self, data: Dict[str, Any]) -> str:
        """åˆ›å»ºä¼˜åŒ–çš„åˆ†ææç¤º - å¼ºè°ƒç›®æ ‡ä»·ä½å’Œæ­¢æŸ"""
        market_data = data.get('market', {})
        macro_data = data.get('macro_economic', {})
        news_data = data.get('news', {})
        multi_tf_data = data.get('multi_timeframe', {})

        current_price = market_data.get('current_price', 0)

        prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„åŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“åˆ†æå¸ˆã€‚è¯·åŸºäºä»¥ä¸‹æ•°æ®æä¾›å…·ä½“çš„äº¤æ˜“å»ºè®®ï¼Œé‡ç‚¹ç»™å‡ºæ˜ç¡®çš„ç›®æ ‡ä»·ä½å’Œæ­¢æŸä½ã€‚

ğŸ“ˆ å½“å‰å¸‚åœºæ¦‚å†µï¼š
- äº¤æ˜“å¯¹: {market_data.get('symbol', 'N/A')}
- å½“å‰ä»·æ ¼: ${current_price:,.2f}
- RSI(14): {market_data.get('rsi', 50):.1f}
- MACD: {market_data.get('macd', 'N/A')}
- å¸ƒæ—å¸¦: {market_data.get('bb_position', 'N/A')}

ğŸ“Š å¤šæ—¶é—´æ¡†æ¶å¿«é€Ÿè§£è¯»ï¼š"""

        # ç®€åŒ–å¤šæ—¶é—´æ¡†æ¶æ•°æ®å±•ç¤º
        if multi_tf_data:
            for tf, indicators in multi_tf_data.items():
                if indicators:
                    rsi = indicators.get('rsi', 'N/A')
                    bb = indicators.get('bb_position', 'N/A')
                    rsi_val = None
                    try:
                        rsi_val = float(rsi)
                    except Exception:
                        rsi_val = None
                    signal = "ä¸­æ€§"
                    if rsi_val is not None:
                        if rsi_val > 70:
                            signal = "è¶…ä¹°"
                        elif rsi_val < 30:
                            signal = "è¶…å–"
                    prompt += f"\n- {tf}: RSI={rsi} ({signal}), å¸ƒæ—å¸¦{bb}"

        prompt += f"""

ğŸŒ å®è§‚ç¯å¢ƒç®€è¦ï¼š
- ç¾è”å‚¨ç«‹åœº: {macro_data.get('fed_sentiment', 'N/A')}
- VIXæŒ‡æ•°: {macro_data.get('vix_level', 'N/A')} (ææ…Œç¨‹åº¦)
- æ–°é—»æƒ…ç»ª: {news_data.get('sentiment_score', 0):+.1f}

ğŸ“‹ åˆ†æè¦æ±‚ï¼š
è¯·é‡ç‚¹æä¾›ä»¥ä¸‹å†…å®¹ï¼š

1. å¸‚åœºçŠ¶æ€åˆ¤æ–­ (ç®€è¦):
   - å½“å‰è¶‹åŠ¿æ–¹å‘å’Œå¼ºåº¦
   - å¤šæ—¶é—´æ¡†æ¶æ˜¯å¦ä¸€è‡´
   - å…³é”®é˜»åŠ›æ”¯æ’‘ä½

2. å…·ä½“äº¤æ˜“å»ºè®®:
   - æ“ä½œæ–¹å‘: ä¹°å…¥/å–å‡º/è§‚æœ›
   - å…·ä½“åŸå›  (1-2å¥è¯)
   - æœ€ä½³è¿›åœºæ—¶æœº

3. å…³é”®ä»·ä½è®¾å®š (å¿…é¡»æä¾›):
   - ç›®æ ‡ä»·ä½1: ä¿å®ˆç›®æ ‡ (å½“å‰ä»·æ ¼Â±3-5%)
   - ç›®æ ‡ä»·ä½2: æ¿€è¿›ç›®æ ‡ (å½“å‰ä»·æ ¼Â±8-12%)
   - æ­¢æŸä»·ä½: ä¸¥æ ¼æ­¢æŸ (å½“å‰ä»·æ ¼Â±2-4%)
   - åŠ ä»“ä»·ä½: å¦‚æœçœ‹æ¶¨ï¼Œå›è°ƒåŠ ä»“ä½

4. é£é™©æç¤º:
   - ä¸»è¦é£é™©ç‚¹
   - æ­¢æŸå¿…è¦æ€§

è¯·ç›´æ¥ç»™å‡ºç»“è®ºï¼Œé¿å…å†—é•¿åˆ†æã€‚æœ€åå¿…é¡»æä¾›æ ‡å‡†JSONæ ¼å¼ç»“æœï¼š

{{"trend": "çœ‹æ¶¨/çœ‹è·Œ/ä¸­æ€§", "action": "ä¹°å…¥/å–å‡º/è§‚æœ›", "confidence": 0.75, "technical_score": 7.5, "macro_score": 6.0, "risk_level": 4, "target_price_1": {current_price * 1.05:.0f}, "target_price_2": {current_price * 1.10:.0f}, "stop_loss": {current_price * 0.97:.0f}, "add_position_price": {current_price * 0.98:.0f}, "timeframe_summary": "å¤šæ—¶é—´æ¡†æ¶æ€»ç»“", "key_reason": "å…³é”®äº¤æ˜“ç†ç”±"}}

æ³¨æ„ï¼šJSONä¸­æ•°å€¼ä¸åŠ å¼•å·ï¼Œå­—ç¬¦ä¸²ç”¨åŒå¼•å·ã€‚
"""
        return prompt
    
    def _parse_ai_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æAIå“åº” - å¢å¼ºç‰ˆï¼Œæ”¯æŒå¤šä¸ªç›®æ ‡ä»·ä½å’Œé”™è¯¯å¤„ç†"""
        try:
            # è®°å½•åŸå§‹å“åº”ç”¨äºè°ƒè¯•
            logger.debug(f"OpenAIåŸå§‹å“åº”: {response_text[:500]}...")
            
            # å°è¯•è§£æJSONéƒ¨åˆ† - å¤šç§åŒ¹é…ç­–ç•¥
            import re
            
            # ç­–ç•¥1: å¯»æ‰¾å®Œæ•´çš„JSONå¯¹è±¡
            json_patterns = [
                r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',  # åµŒå¥—JSON
                r'\{[^{}]+\}',  # ç®€å•JSON
                r'```json\s*(\{.*?\})\s*```',  # Markdownä»£ç å—ä¸­çš„JSON
                r'```\s*(\{.*?\})\s*```'  # æ™®é€šä»£ç å—ä¸­çš„JSON
            ]
            
            json_data = None
            for pattern in json_patterns:
                matches = re.findall(pattern, response_text, re.DOTALL)
                for match in matches:
                    try:
                        # æ¸…ç†JSONå­—ç¬¦ä¸²
                        clean_json = match.strip()
                        # æ›¿æ¢å¸¸è§çš„æ ¼å¼é—®é¢˜
                        clean_json = clean_json.replace("'", '"')  # å•å¼•å·æ”¹åŒå¼•å·
                        clean_json = re.sub(r'(\w+):', r'"\1":', clean_json)  # å±æ€§ååŠ å¼•å·
                        clean_json = re.sub(r':\s*([^",\[\{][^,\]\}]*)', r': "\1"', clean_json)  # å€¼åŠ å¼•å·
                        
                        json_data = json.loads(clean_json)
                        logger.info(f"JSONè§£ææˆåŠŸï¼Œä½¿ç”¨æ¨¡å¼: {pattern}")
                        break
                    except json.JSONDecodeError as je:
                        logger.debug(f"JSONè§£æå¤±è´¥ (æ¨¡å¼{pattern}): {je}")
                        continue
                if json_data:
                    break
            
            if json_data:
                # æå–è¯¦ç»†åˆ†ææ–‡æœ¬
                full_analysis = response_text
                
                # å®‰å…¨çš„æ•°å€¼è½¬æ¢å‡½æ•°
                def safe_float(value, default=0.5):
                    try:
                        if isinstance(value, (int, float)):
                            return float(value)
                        if isinstance(value, str):
                            # ç§»é™¤éæ•°å­—å­—ç¬¦ï¼Œä¿ç•™å°æ•°ç‚¹å’Œè´Ÿå·
                            cleaned = re.sub(r'[^\d\.\-]', '', str(value))
                            return float(cleaned) if cleaned else default
                        return default
                    except:
                        return default
                
                def safe_float_or_none(value):
                    """å®‰å…¨è½¬æ¢æ•°å€¼ï¼Œå¤±è´¥æ—¶è¿”å›None"""
                    try:
                        if value is None:
                            return None
                        if isinstance(value, (int, float)):
                            return float(value)
                        if isinstance(value, str):
                            cleaned = re.sub(r'[^\d\.\-]', '', str(value))
                            return float(cleaned) if cleaned else None
                        return None
                    except:
                        return None
                
                def safe_int(value, default=5):
                    try:
                        if isinstance(value, (int, float)):
                            return int(value)
                        if isinstance(value, str):
                            cleaned = re.sub(r'[^\d\-]', '', str(value))
                            return int(cleaned) if cleaned else default
                        return default
                    except:
                        return default
                
                # å¢å¼ºè¿”å›æ•°æ® - æ”¯æŒå¤šä¸ªç›®æ ‡ä»·ä½
                result = {
                    "trend": str(json_data.get("trend", "ä¸­æ€§")),
                    "action": str(json_data.get("action", "è§‚æœ›")), 
                    "confidence": safe_float(json_data.get("confidence", 0.5)),
                    "technical_score": safe_float(json_data.get("technical_score", 5.0)),
                    "macro_score": safe_float(json_data.get("macro_score", 5.0)),
                    "sentiment_score": safe_float(json_data.get("sentiment_score", 5.0)),
                    "risk_level": safe_int(json_data.get("risk_level", 5)),
                    "target_price": safe_float_or_none(json_data.get("target_price_1") or json_data.get("target_price")),
                    "target_price_1": safe_float_or_none(json_data.get("target_price_1")),
                    "target_price_2": safe_float_or_none(json_data.get("target_price_2")),
                    "stop_loss": safe_float_or_none(json_data.get("stop_loss")),
                    "add_position_price": safe_float_or_none(json_data.get("add_position_price")),
                    "timeframe_summary": str(json_data.get("timeframe_summary", "å¤šæ—¶é—´æ¡†æ¶åˆ†æ")),
                    "key_reason": str(json_data.get("key_reason") or json_data.get("reasoning", "AIç»¼åˆåˆ†æ")),
                    "reasoning": str(json_data.get("key_reason") or json_data.get("reasoning", "AIç»¼åˆåˆ†æ")),
                    "full_analysis": full_analysis  # ä¿å­˜å®Œæ•´åˆ†ææ–‡æœ¬
                }
                
                logger.info(f"AIåˆ†æå®Œæˆ: {result['trend']} - {result['action']} (ç›®æ ‡: {result.get('target_price_1', 'N/A')}, æ­¢æŸ: {result.get('stop_loss', 'N/A')})")
                return result
                
        except Exception as e:
            logger.error(f"JSONè§£æè¿‡ç¨‹å‡ºé”™: {e}")
            # è®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
            import traceback
            logger.debug(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        
        # å¦‚æœJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬åˆ†æ
        logger.info("JSONè§£æå¤±è´¥ï¼Œå¯ç”¨æ–‡æœ¬åˆ†ææ¨¡å¼")
        analysis = {
            "trend": "ä¸­æ€§",
            "action": "è§‚æœ›",
            "confidence": 0.5,
            "technical_score": 5.0,
            "macro_score": 5.0,
            "sentiment_score": 5.0,
            "risk_level": 5,
            "reasoning": "æ–‡æœ¬åˆ†ææ¨¡å¼",
            "full_analysis": response_text or "AIåˆ†æä¸å¯ç”¨",
            "target_price": None,
            "target_price_1": None,
            "target_price_2": None,
            "stop_loss": None,
            "add_position_price": None,
            "timeframe_summary": "å¤šæ—¶é—´æ¡†æ¶åˆ†æ",
            "key_reason": "åŸºäºå…³é”®è¯çš„ç®€åŒ–åˆ†æ"
        }
        
        # ç®€å•çš„å…³é”®è¯åˆ†æ
        text_lower = response_text.lower() if response_text else ""
        
        if any(word in text_lower for word in ["çœ‹æ¶¨", "ä¹°å…¥", "ä¸Šæ¶¨", "bullish", "å¼ºçƒˆä¹°å…¥", "å»ºè®®ä¹°å…¥"]):
            analysis["trend"] = "çœ‹æ¶¨"
            analysis["action"] = "ä¹°å…¥"
            analysis["confidence"] = 0.7
        elif any(word in text_lower for word in ["çœ‹è·Œ", "å–å‡º", "ä¸‹è·Œ", "bearish", "å¼ºçƒˆå–å‡º", "å»ºè®®å–å‡º"]):
            analysis["trend"] = "çœ‹è·Œ" 
            analysis["action"] = "å–å‡º"
            analysis["confidence"] = 0.7
        elif any(word in text_lower for word in ["éœ‡è¡", "æ•´ç†", "è§‚æœ›", "ç­‰å¾…", "hold"]):
            analysis["trend"] = "éœ‡è¡"
            analysis["action"] = "è§‚æœ›"
            analysis["confidence"] = 0.6
        
        return analysis
    
    def _fallback_analysis(self, data: Dict[str, Any], reason: Optional[str] = None) -> Dict[str, Any]:
        """é™çº§åˆ†æ - åŸºäºè§„åˆ™çš„ç®€å•åˆ†æ"""
        market_data = data.get('market', {})
        macro_data = data.get('macro_economic', {})
        news_data = data.get('news', {})
        
        # åŸºç¡€è¯„åˆ†è®¡ç®—
        score = 0
        confidence = 0.6  # åŸºç¡€åˆ†æç½®ä¿¡åº¦è¾ƒä½
        
        # æŠ€æœ¯æŒ‡æ ‡è¯„åˆ†
        if 'rsi' in market_data:
            rsi = market_data['rsi']
            if rsi < 30:
                score += 0.3  # è¶…å–
            elif rsi > 70:
                score -= 0.3  # è¶…ä¹°
        
        # å®è§‚ç»æµè¯„åˆ†
        if 'macro_impact_score' in macro_data:
            score += macro_data['macro_impact_score'] * 0.4
        
        # æ–°é—»æƒ…ç»ªè¯„åˆ†
        if 'sentiment_score' in news_data:
            score += news_data['sentiment_score'] * 0.3
        
        # è½¬æ¢ä¸ºå†³ç­–
        if score > 0.2:
            trend = "çœ‹æ¶¨"
            action = "ä¹°å…¥"
            risk_level = "ä¸­"
        elif score < -0.2:
            trend = "çœ‹è·Œ"
            action = "å–å‡º"
            risk_level = "ä¸­"
        else:
            trend = "ä¸­æ€§"
            action = "æŒæœ‰"
            risk_level = "ä½"
        
        return {
            "trend": trend,
            "risk_level": risk_level,
            "action": action,
            "confidence": confidence,
            "reasoning": f"åŸºäºè§„åˆ™åˆ†æï¼Œç»¼åˆè¯„åˆ†: {score:.2f}",
            "analysis_type": "fallback",
            "openai_error": reason
        }

# å…¨å±€åˆ†æå™¨å®ä¾‹
_global_analyzer = None

def get_openai_analyzer(api_key: Optional[str] = None, base_url: Optional[str] = None) -> OpenAIAnalyzer:
    """è·å–OpenAIåˆ†æå™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _global_analyzer
    
    if _global_analyzer is None:
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®ä¸­è·å–é»˜è®¤å€¼
        if api_key is None:
            import os
            api_key = os.getenv("OPENAI_API_KEY", "")
        
        if base_url is None:
            import os
            base_url = os.getenv("OPENAI_BASE_URL", "https://jeniya.cn/v1")
        
        _global_analyzer = OpenAIAnalyzer(api_key=api_key, base_url=base_url)
        logger.info(f"Created OpenAI analyzer instance: available={_global_analyzer.is_available}")
    
    return _global_analyzer

# æµ‹è¯•å‡½æ•°
async def test_analyzer():
    """æµ‹è¯•åˆ†æå™¨åŠŸèƒ½"""
    analyzer = OpenAIAnalyzer(api_key="sk-test")
    
    test_data = {
        'market': {
            'current_price': 50000,
            'trend': 'upward',
            'rsi': 45
        },
        'macro_economic': {
            'nasdaq_change': 1.2,
            'vix_level': 18,
            'fed_sentiment': 'neutral',
            'macro_impact_score': 0.1
        },
        'news': {
            'sentiment_score': 0.2
        }
    }
    
    print("ğŸ§ª æµ‹è¯•OpenAIåˆ†æå™¨...")
    result = await analyzer.analyze_comprehensive(test_data)
    
    print(f"åˆ†æç»“æœ:")
    print(f"  è¶‹åŠ¿: {result.get('trend', 'N/A')}")
    print(f"  å»ºè®®: {result.get('action', 'N/A')}")
    print(f"  é£é™©: {result.get('risk_level', 'N/A')}")
    print(f"  ç½®ä¿¡åº¦: {result.get('confidence', 0):.2f}")
    print(f"  åˆ†æç±»å‹: {result.get('analysis_type', 'AI')}")
    
    return analyzer.is_available

if __name__ == "__main__":
    asyncio.run(test_analyzer())
